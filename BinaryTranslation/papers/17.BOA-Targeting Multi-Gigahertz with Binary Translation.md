## BOA: Targeting Multi-Gigahertz with Binary Translation

BOA (Binary-translation Optimized Architecture) is a processor designed to **achieve high frequency** by using software dynamic binary translation. Processors for software binary translation are very conducive to high frequency because they **can assume a simple hardware design**.

### 1. Binary Translation Strategy

The overall strategy of binary translation is to translate a PowerPC instruction flow into a set of BOA instruction groups which are then stored in memory and executed natively. These optimized groups are generally **much larger than a basic block** and can contain many branches. The last instruction in each BOA group is **a direct branch** to the next group stored in memory. A group can also be terminated if the total number of operations in it exceeds a certain value or if the number of store operations in it exceeds the number of entries in the store buffer. As long as **a translation exists** for the address pointed to by the final branch in a group, the new groups is **fetched and executed**. If the code does not exist, the machine **re-enters interpretation mode** to slowly execute PowerPC instructions and possibly build more BOA groups. Likewise, if a branch is encountered within the BOA group that is **mispredicted**, native execution must be **halted**, and a branch is taken back to the interpreter. 

#### 1.1. Group Formation

BOA instruction groups are formed along a single path after interpreting the entry point of a PowerPC instruction sequence **15 times**. Once the group entry has been seen 15 times, the code starting at the entry point is **assembled into a PowerPC group**, and **translated into BOA instruction groups** for efficient execution on the underlying hardware.

During BOA’s interpretation phase, statistics are kept on **the number of times each conditional branch is executed** as well as on the total number of times it is taken, thus allowing a dynamic assessment of the probability the branch is taken.

#### 1.2. Scheduling

The BOA operations are then scheduled **greedily**, i.e. at the earliest possible time when 

(1) all input operands are available;

(2) there is a function unit available on which to execute the operation;

(3) there is a free register in which to put the result.

### 2. BOA Architecture Support for Binary Translation

#### 2.1. Instruction Set Architecture

BOA is an unexposed architecture with an instruction set specifically designed to support binary translation. The architecture  provides a number of primitives and resources to make it a good target for binary translation. These primitives include **instructions** to support the efficient execution of the translated code and **the binary translation firmware**.

BOA uses a statically-scheduled, compressed instruction format, similar to a variable length VLIW architecture. A parallel instruction, hereafter referred to as a “**packet**”, **can simultaneously issue up to six operations per cycle**. Code generation guarantees that no dependencies exist between operations in a packet, so they can safely be issued in parallel.

To ensure efficient memory layout, **operations are packed into 128-bit bundles** containing three operations. Bundles are distinct from packets in that a bundle defines **a group of three not -necessarily parallel operations aligned on 128-bit boundaries**, while a packet defines **a variable-sized group of parallel operations (up to six) that is not aligned in memory**.

The BOA architecture defines execution primitives similar to the PowerPC architecture in both semantics and scope.

The BOA architecture provides extra machine registers to support efficient code scheduling and aggressive speculation using register renaming.

The checkpointing mechanism allows the implementation of precise exceptions by all registers containing the PowerPC machine state.

Speculative execution is further supported by speculative load operations, which query the TLB for access mode information.

To enable static reordering of loads, additional hardware support is provided for the two memory ports in the load-store unit.

The LRA instructions is a further hardware feature specifically to support binary translation which is used to check whether the page mapping has been modified since the code was generated.

#### 2.2. Implementation

![](https://github.com/UtopianFuture/UtopianFuture.github.io/blob/master/image/17.1.png?raw=true) 

there are four techniques support dynamic scheduling and dynamic branch prediction:

(1) register scoreboarding;

(2) provides load and store queues for checking for address conflicts between loads and stores which have been reordered during translation;

(3) use of instruction buffers to decouple the fetch pipeline from the execute pipeline;

(4) a novel pipeline control method that enables the pipeline to automatically advance on each processor cycle.