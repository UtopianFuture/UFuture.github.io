## 二进制翻译中的库函数处理和代码Cache管理

### 1. 一些背景知识

（1）静态翻译器因为**无法得知间接控制转移的目标地址，因此可能无法完整地翻译一个程序**，需要依赖解释器的支持,才能完成全部的翻译。

（2）动态翻译过程受到动态执行的限制而不能进行更全面细致的优化，使得翻译生成的代码效率比静态翻译器较差。

（3）动静结合。优化以静态为主，对翻译出来的本地码进行深度优化，避免动态优化本身的时间消耗。动态通过翻译执行本地码，把静态不能识别的间接入口点传给静态帮助其扩大翻译优化的范围。经过动静多遍迭代，最后几乎所有的本地代码都由静态翻译产生。

（4）系统级二进制翻译系统需要在目标机器平台上模拟整个源机器平台的硬件，不仅包括模拟源机器平台的指令，而且需要模拟内存管理单元，外设管理等等，因而能够在二进制翻译系统的支持下启动源机器的整个操作系统，然后在这个操作系统之上再执行所有的源机器应用程序。就相当于一个系统级虚拟机。系统级二进制翻译系统比应用级二进制翻译系统更加复杂，其运行效率一般也会低于应用程序级翻译，但是可以解决应用级二进制翻译系统因为底层差异而解决不了的问题，适用性更强。

（5）动态优化技术是在应用程序的运行时刻对程序的信息进行收集和分析，并对程序的关键段(热路径)进行必要的优化，从而提高程序的性能。

### 2. 二进制翻译中的库函数处理

不同ISA系统平台上传递参数和返回值的方式有较大的差异，为了在目标机上正确执行动态编译的源二进制代码（和我们目前能翻译的静态编译过的程序不同），必须消除这种差异，而消除差异的同时必然会带来执行效率的下降。二进制代码中会频繁的调用系统库函数，因此，对库函数调用的处理既关系到程序执行的正确性，又涉及到翻译后代码的质量以及执行效率。

JLSCL (jacket library and shortcut library)——基于动静结合二进制翻译技术的库函数处理算法。这个算法主要是一种对系统库函数分类处理的思想，将系统库函数分为**可包装库函数**和**PLT****短路库函数**两类，对分类后的库函数采用两种有效的算法(jacket library disposing, JLD和shortcut library disposing, SCLD)分别处理，消除不同ISA之间库函数调用的差异性，同时兼顾执行速度和管理维护的便捷性。

#### 2.1. 处理库函数调用过程中遇到的问题

- 结构变量对齐问题。由于源和目标ISA系统平台对于某些数据类型的对齐方式可能不同，因此一个结构变量的某些域变量相对于结构变量起始存储位置有不同的偏移，当库函数要访问这个结构变量时，就可能发生域变量的错误引用；或者由于源与目标ISA的同名结构变量中域变量的个数不同，因此源ISA结构变量中的某个域可能在目标ISA上根本没有，反之亦然。
- 同名全局变量在不同文件有多个副本。源二进制代码与本地系统库分属于不同的ISA，就无法在链接过程中进行重定位来保证全局变量副本的唯一。

#### 2.2. 库函数处理算法设计

- 可包装库函数。如果某个库函数没有同名全局变量多副本和结构变量对齐差异这两类问题，那么可以调用目标机本地的库函数。那如果本地没有对应的库函数，就只能翻译源平台的库函数。
- PLT短路库函数。有些库函数在静态阶段已经翻译过，动态阶段可以直接跳入静态本地码中，或有些库函数虽然在初始的静态阶段没有被翻译，但可以采用回填的方法在库函数代码被翻译之后填写目标地址。

##### 2.2.1. JLSCL 算法设计

JLSCL 包含两个算法：JLD 算法和SCLD 算法。

- JLD 算法：把基本块内为了翻译参数压栈指令而生成的本地码，修改成把参数按照目标机ABI 的传参约定放入到相应的寄存器和堆栈的本地代码，然后再调用本地库函数。
- SCLD 算法：调用静态翻译出来的高质量源平台库函数的本地码。首先要在已经翻译的本地码中查找当前要处理的库函数的本地码，对于查找不成功的情况采用回填技术处理。

### 3. 代码 Cache 的分级双粒度管理策略

动态二进制翻译中一类比较重要的问题是如何管理翻译出来的目标机本地代码，既要尽可能少地占用内存空间，又要减少由于代码Cache的替换操作造成的性能下降。

#### 3.1. 常见的 Cache 管理策略

- 不替换策略：在代码Cache中从低地址到高地址依次存放每个代码块，由于空间足够大，不会出现本地码的替换，只有本地码第一次翻译时发生Cache不命中。这种策略是用大量牺牲内存的方式来换取时间上的优势，但是会给硬件的内存容量带来压力。
- 全清空策略：在代码Cache中从低地址到高地址依次存放每个代码块，当Cache空间不足或程序阶段行为突变时，清空整个Cache。
- FIFO 策略：在代码Cache中从低地址到高地址依次存放每个代码块，当Cache空间不足时，按 “先进先出”顺序把最先进入Cache的代码块替换出去，如果空间仍然不足，就继续把物理上相邻的代码块也替换出去，直至有足够的空间来存放代码块。

#### 3.2. 本地码的链接和断链

在翻译执行目标机本地码的过程中，存在翻译控制器和本地码之间的上下文切换，会带来很大开销。一种解决办法就是记录X86二进制代码的前驱后继关系，把本地码按照逻辑上的执行顺序链接起来，减少切换次数，直到所需的本地码不在代码Cache中，才发生上下文切换来翻译执行后续的X86代码。

#### 3.3. LRC 策略的代码 Cache 模型

LRC策略把代码Cache按照所存储的本地码的执行热度分成上下两级，大小的比例是1:4。上级Cache存储热度较高的本地码，本地码首先存入下级Cache，达到一定热度后会被提升到上级。下级本地码被替换时会从Cache中替换出去，而上级本地码被替换时被换到下级Cache中。